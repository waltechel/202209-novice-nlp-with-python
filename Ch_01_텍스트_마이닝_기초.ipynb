{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN5NEKFMRxqjLr9eGPolapG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltechel/202209-novice-nlp-with-python/blob/master/Ch_01_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%A7%88%EC%9D%B4%EB%8B%9D_%EA%B8%B0%EC%B4%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01 텍스트 마이닝 기초\n",
        "\n",
        "## 1.1 텍스트 마이닝의 정의\n",
        "\n",
        "- 교재 4페이지에 다음과 같은 내용이 있습니다.\n",
        "  > “크기가 큰 경우에는 벡터를 구성하는 많은 값(많게는 99%이상)들이 0이고 극히 일부만 0이 아닌 값들을 갖게 되는데, 이것을 희소(sparse)하다고 말한다. 반면, 크기가 작은 경우에는 **`벡터가 대부분 0인 값들로 이루어지고`**, 이것을 밀집(dense)돼 있다고 말한다.”\n",
        "- 제가 읽었을 때는 희소와 밀집된 벡터의 표현이, 길고 짧은 차이 외에는 동일한 설명처럼 이해가 됩니다. **‘값이 대부분 0’** 이라고… 제가 이해한 것이 맞는 것일까요? 붉은 색으로 강조한 부분에 의문이 생겼는데요. 두 벡터 표현이 ‘길이’ 외에 어떤 차이가 있을까요?"
      ],
      "metadata": {
        "id": "f_KKXSVKasd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 희소 벡터를 구현한 사례\n",
        "  - 다음은 자연어를 원핫 벡터로 만든 사례이다\n",
        "  - 이 경우 각 열이 어떤 단어에 대응되는지에 대한 정보를 미리 안다면 원핫 벡터에서 자연어를 완벽하게 복원하는 것도 가능하다.\n",
        "  - 다만 이런 접근 방식을 취할 때는 차원의 크기가 너무 커질 가능성이 높다.\n",
        "  - 절대 다수의 값이 0이며 1인 값은 자연어 토큰의 개수 정도이다."
      ],
      "metadata": {
        "id": "Ji4kyA8OhdUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSKm1Hm8aUm3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "sentence = sentence = \"자연어 처리는 인공지능의 한 분야로서 머신러닝을 사용하여 텍스트와 데이터를 처리하고 해석합니다.\\n자연어 처리에서 언급되는 자연어는 인공 언어와 대치되는 개념이다.\"\n",
        "token_sequence = str.split(sentence)\n",
        "vocab = sorted(set(token_sequence))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "', '.join(vocab)"
      ],
      "metadata": {
        "id": "-450vYZqe-_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(token_sequence)\n",
        "vocab_size = len(vocab)\n",
        "onehot_vectors = np.zeros((num_tokens, vocab_size), int)"
      ],
      "metadata": {
        "id": "CROrxFORcvyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_vectors"
      ],
      "metadata": {
        "id": "yx-qJdVPdbKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, word in enumerate(token_sequence):\n",
        "  print(i, word, vocab.index(word))\n",
        "  onehot_vectors[i, vocab.index(word)] = 1"
      ],
      "metadata": {
        "id": "bI_c1PUXeLPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(vocab)"
      ],
      "metadata": {
        "id": "uIh2QvAeeUct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_vectors"
      ],
      "metadata": {
        "id": "ZegZgPoMeXVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(onehot_vectors, columns=vocab)"
      ],
      "metadata": {
        "id": "JMHiwWW4f5cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 밀집 벡터를 구현한 사례\n",
        "  - 다음은 자연어를 밀집 벡터(단어 빈도 벡터)로 구현한 사례이다.\n",
        "  - 이 경우 밀집 벡터에서 자연어를 복구하는 것은 불가능하다. 그러나 이 경우에도 주요 의미를 포착하는 것은 가능하다.\n",
        "  - 이 경우 단어 사전이 차원이 되므로 희소 행렬보다는 조금 더 밀집한 결과를 얻을 수 있다.\n",
        "  - 문맥에 관한 정보를 알 수 없다는 약점이 있으나, 그를 방지하기 위해 n-gram 기법을 사용하기도 한다.\n",
        "    - n-gram 기법을 사용하게 되면 단어 하나로 된 토큰이라는 개념을 n개의 단어로 이루어진 토큰인 n-gram을 활용할 수 있으므로 **문맥을 조금 더 반영할 수 있다.**"
      ],
      "metadata": {
        "id": "P00vJLcuiT3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_bow = {}\n",
        "for token in sentence.split():\n",
        "  if token in sentence_bow:\n",
        "    sentence_bow[token] += 1\n",
        "  else:\n",
        "    sentence_bow[token] = 1"
      ],
      "metadata": {
        "id": "2jBho0yghWTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_bow"
      ],
      "metadata": {
        "id": "bE4NkoyXjevb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(pd.Series(dict([(token, sentence_bow[token]) for token in sentence.split()])), columns = ['sent']).T\n",
        "df"
      ],
      "metadata": {
        "id": "nS_YEqOpjgSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import core\n",
        "corpus = {}\n",
        "for i, sent in enumerate(sentence.split('\\n')):\n",
        "  corpus['sent{}'.format(i)] = dict((tok, 1) for tok in sent.split())\n",
        "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
        "df"
      ],
      "metadata": {
        "id": "Ii7gOfXokLrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.T"
      ],
      "metadata": {
        "id": "T9LVwNKJl07d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다음과 같이 내적(점곱)을 활용하게 되면 두 개의 문장에 공통적으로 등장하는 단어가 몇 개인지 알 수 있다."
      ],
      "metadata": {
        "id": "1hC5BROBnKVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sent0.dot(df.sent1)"
      ],
      "metadata": {
        "id": "WH8x0GdBmCFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y56skwMtmFAe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}