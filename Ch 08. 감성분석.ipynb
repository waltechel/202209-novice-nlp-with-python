{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waltechel/202209-novice-nlp-with-python/blob/master/Ch%2008.%20%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi55AJnRxwRA"
      },
      "source": [
        "# Chapter 8. 감성 분석\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1 감성분석의 이해\n",
        "\n",
        "감성분석은 텍스트에 나타난 의견, 평가, 태도와 같은 주관적인 정보를 분석하는 것을 말한다. \n",
        "\n",
        "감성분석 방법론은 다양하게 분류될 수 있는데, 크게는 어휘 기반 분석과 기계학습 기반의 분석으로 나뉘어진다.\n",
        "\n",
        "### 8.1.1 어휘 기반의 감성 분석\n",
        "\n",
        "감성사전으로부터 각 단어들에 대한 감성 값을 가져온 후에 이를 조합해 텍스트에 대한 감성을 계산하는 다양한 방법이 있다. \n",
        "\n",
        "이와 같은 문제점을 극복하기 위해 문장의 형태소를 분석하고 다시 이를 명사구, 형용사구와 같은 구로 묶는 청킹을 한 후에 밑의 단어로부터 상위의 구로 이동하면서 단계적으로 긍정/부정을 결정하는 방식도 있다. \n",
        "\n"
      ],
      "metadata": {
        "id": "5bof1s7fxzQ5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDoqYKzexwRQ"
      },
      "source": [
        "## 8.2 감성 사전을 이용한 영화 리뷰 감성 분석\n",
        "\n",
        "### 8.2.1 NLTK 영화 리뷰 데이터 준비\n",
        "\n",
        "1: https://www.nltk.org/book/ch02.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KCix9xivxwRV",
        "outputId": "b0f6c4d0-fcc3-4487-c337-694829abe480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#review count: 2000\n",
            "#samples of file ids: ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n",
            "#categories of reviews: ['neg', 'pos']\n",
            "#num of \"neg\" reviews: 1000\n",
            "#num of \"pos\" reviews: 1000\n",
            "#id of the first review: neg/cv000_29416.txt\n",
            "#part of the first review: plot : two teen couples go to a church party , drink and then drive . \n",
            "they get into an accident . \n",
            "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
            "what's the deal ? \n",
            "watch the movie and \" sorta \" find out . . . \n",
            "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
            "which is what makes this review an even harder one to write , since i generally applaud films which attempt\n",
            "#sentiment of the first review: ['neg']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "print('#review count:', len(movie_reviews.fileids())) #영화 리뷰 문서의 id를 반환\n",
        "print('#samples of file ids:', movie_reviews.fileids()[:10]) #id를 10개까지만 출력\n",
        "print('#categories of reviews:', movie_reviews.categories()) # label, 즉 긍정인지 부정인지에 대한 분류\n",
        "print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) #label이 부정인 문서들의 id를 반환\n",
        "print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) #label이 긍정인 문서들의 id를 반환\n",
        "\n",
        "fileid = movie_reviews.fileids()[0] #첫번째 문서의 id를 반환\n",
        "print('#id of the first review:', fileid)\n",
        "print('#part of the first review:', movie_reviews.raw(fileid)[:500]) #첫번째 문서의 내용을 500자까지만 출력\n",
        "print('#sentiment of the first review:', movie_reviews.categories(fileid)) #첫번째 문서의 감성\n",
        "\n",
        "fileids = movie_reviews.fileids() #movie review data에서 file id를 가져옴\n",
        "reviews = [movie_reviews.raw(fileid) for fileid in fileids] #file id를 이용해 raw text file을 가져옴\n",
        "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByEKc4T3xwRc"
      },
      "source": [
        "### 8.2.2 TextBlob을 이용한 감성 분석\n",
        "\n",
        "1: https://textblob.readthedocs.io/en/dev/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6tASroxxwRd"
      },
      "source": [
        "https://textblob.readthedocs.io/en/dev/quickstart.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7stzXH92xwRd",
        "outputId": "cc295169-95ee-4475-ae0d-1416c07c844a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Collecting textblob\n",
            "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 24.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Installing collected packages: textblob\n",
            "  Attempting uninstall: textblob\n",
            "    Found existing installation: textblob 0.15.3\n",
            "    Uninstalling textblob-0.15.3:\n",
            "      Successfully uninstalled textblob-0.15.3\n",
            "Successfully installed textblob-0.17.1\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextBlog의 사용은 매우 직관적으로, 객체를 생성할 때 대상이 되는 텍스트의 인수를 전달하고 감성 분석의 결과를 sentiment 속성을 통해 확인하면 된다. sentiment는 polarity와 subjectivity로 구성되어 있는데, polarity는 감성을 나타내는 극성을 의미하고 -1.0과 1.0 사이의 실숫값을 가지며 subjectivity는 0.0과 1.0 사이의 실수로 0에 가까울수록 객관적 1에 가까울수록 주관적임을 의미한다. "
      ],
      "metadata": {
        "id": "PK4RQJyvzUdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nv31735qxwRe",
        "outputId": "5da9913b-dbeb-40ab-ca1d-2bcb7a2d9b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.06479782948532947, subjectivity=0.5188408350908352)\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "result = TextBlob(reviews[0])\n",
        "## 극성은 0.06으로 매우 약한 긍정, subjectivity는 0.5로 중간 정도임을 알 수 있다.\n",
        "print(result.sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sMa8TDLexwRf"
      },
      "outputs": [],
      "source": [
        "def sentiment_TextBlob(docs):\n",
        "    results = []\n",
        "\n",
        "    for doc in docs:\n",
        "        testimonial = TextBlob(doc)\n",
        "        if testimonial.sentiment.polarity > 0:\n",
        "            results.append('pos')\n",
        "        ## 일반적으로 0이면 부정으로 처리한다.\n",
        "        else:\n",
        "            results.append('neg')\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "os_cVIPexwRg",
        "outputId": "5f2c4207-acf6-42a4-d620-74f797afc27c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#TextBlob을 이용한 리뷰 감성분석의 정확도: 0.6\n"
          ]
        }
      ],
      "source": [
        "# 지금까지는 정확도 함수를 라이브러리에서 가져와서 사용했지만 TextBlob은 제공 안하므로 사이킷런에서 가져온다.\n",
        "# 정확도가 별로 안좋다.\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('#TextBlob을 이용한 리뷰 감성분석의 정확도:', accuracy_score(categories, sentiment_TextBlob(reviews)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy--M4pgxwRh"
      },
      "source": [
        "### 8.2.3 AFINN을 이용한 감성 분석\n",
        "\n",
        "https://github.com/fnielsen/afinn \n",
        "\n",
        "(1) http://corpustext.com/reference/sentiment_afinn.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vi6RoLM9xwRi",
        "outputId": "e6a17e57-7dc8-4bd5-dadb-9183e33271b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting afinn\n",
            "  Downloading afinn-0.1.tar.gz (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51 kB 33.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53447 sha256=a32f63c01df56800cc74fd19c7100a1f9c622f762423153cfb2d8093fe761fe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/16/3a/9f0953027434eab5dadf3f33ab3298fa95afa8292fcf7aba75\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ]
        }
      ],
      "source": [
        "# 수작업의 목록을 담보할 수 있는가?\n",
        "!pip install afinn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NhwLtWELxwRj",
        "outputId": "dbf4d987-c8e7-41e3-c6b6-85f38113b58e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Afinn을 이용한 리뷰 감성분석의 정확도: 0.664\n"
          ]
        }
      ],
      "source": [
        "from afinn import Afinn\n",
        "\n",
        "def sentiment_Afinn(docs):\n",
        "    afn = Afinn(emoticons=True)\n",
        "    results = []\n",
        "\n",
        "    for doc in docs:\n",
        "        if afn.score(doc) > 0:\n",
        "            results.append('pos')\n",
        "        else:\n",
        "            results.append('neg')\n",
        "    return results\n",
        "\n",
        "print('#Afinn을 이용한 리뷰 감성분석의 정확도:', accuracy_score(categories, sentiment_Afinn(reviews)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P7DTu6DxwRk"
      },
      "source": [
        "### 8.2.4 VADER를 이용한 감성 분석\n",
        "\n",
        "- 규칙 기반의 알고리즘을 사용하는 것으로 알려져 있으며 트위터나 페이스북 등에서 좋은 성능이 나올 수 있도록 개발했다.\n",
        "\n",
        "(1) https://github.com/cjhutto/vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UbjZ2TWmxwRk",
        "outputId": "377e3b23-fe8b-40b0-be40-b22c7d2533d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoDt-JuuxwRl",
        "outputId": "4d49cec3-ce30-49aa-d7db-3a837babcf07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Vader을 이용한 리뷰 감성분석의 정확도: 0.635\n"
          ]
        }
      ],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "def sentiment_vader(docs):\n",
        "    analyser = SentimentIntensityAnalyzer()\n",
        "    results = []\n",
        "\n",
        "    for doc in docs:\n",
        "        score = analyser.polarity_scores(doc)\n",
        "        if score['compound'] > 0:\n",
        "            results.append('pos')\n",
        "        else:\n",
        "            results.append('neg')\n",
        "\n",
        "    return results\n",
        "\n",
        "print('#Vader을 이용한 리뷰 감성분석의 정확도:', accuracy_score(categories, sentiment_vader(reviews)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ommaROUsxwRm"
      },
      "source": [
        "### 8.2.5 한글 감성사전\n",
        "\n",
        "1: https://github.com/park1200656/KnuSentiLex   \n",
        "2: https://github.com/mrlee23/KoreanSentimentAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoPVJG6vxwRo"
      },
      "source": [
        "## 8.3 학습을 통한 머신러닝 기반의 감성 분석\n",
        "\n",
        "### 8.3.1 NLTK 영화 리뷰에 대한 머신러닝 기반 감성 분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 학습 데이터와 테스트 데이터로 나눠준다."
      ],
      "metadata": {
        "id": "QyLrlbHQ13T5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q2DApmJDxwRp",
        "outputId": "74b63c05-12e1-4d07-a808-6806aa3c710f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set count:  1600\n",
            "Test set count:  400\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split #sklearn에서 제공하는 split 함수를 사용\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reviews, categories, test_size=0.2, random_state=7)\n",
        "\n",
        "print('Train set count: ', len(X_train))\n",
        "print('Test set count: ', len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런의 TfidfVectorizer를 이용해 TFIDF 벡터로 변환한다. 이후 MultinomialNB를 이용해 나이브 베이즈 모형으로 학습하고 성능을 출력한다."
      ],
      "metadata": {
        "id": "ACNLb19X165S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TfLSa0r2xwRp",
        "outputId": "4600f57f-6ace-49a3-e912-b798c6e4f879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set dimension: (1600, 36189)\n",
            "#Test set dimension: (400, 36189)\n",
            "#Train set score: 0.998\n",
            "#Test set score: 0.797\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB #sklearn이 제공하는 MultinomialNB 를 사용\n",
        "\n",
        "tfidf = TfidfVectorizer().fit(X_train) \n",
        "\n",
        "X_train_tfidf = tfidf.transform(X_train) # train set을 변환\n",
        "print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인\n",
        "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
        "print('#Test set dimension:', X_test_tfidf.shape)\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언\n",
        "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
        "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
        "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "감성 사전을 이용한 감성 분석에 비해 성능이 월등히 뛰어나다. 이는 학습된 모형이 현재의 영화 리뷰 데이터에 최적화되었기 때문이다. "
      ],
      "metadata": {
        "id": "lyRiYoIF2HJC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGG8-lxLxwRq"
      },
      "source": [
        "### 8.3.2 다음 영화 리뷰에 대한 머신러닝 기반 감성 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zg6aQlnVxwRq",
        "outputId": "4ca1a9d1-8725-4f61-ff02-aa05d533c3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  rating        date  \\\n",
              "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
              "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
              "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
              "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
              "4                                               재미있다      10  2018.10.20   \n",
              "\n",
              "    title  \n",
              "0  인피니티 워  \n",
              "1  인피니티 워  \n",
              "2  인피니티 워  \n",
              "3  인피니티 워  \n",
              "4  인피니티 워  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f1829f7-6cb0-438f-bf8d-d341466fa064\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
              "      <td>1</td>\n",
              "      <td>2018.10.29</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
              "      <td>10</td>\n",
              "      <td>2018.10.26</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
              "      <td>8</td>\n",
              "      <td>2018.10.24</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
              "      <td>8</td>\n",
              "      <td>2018.10.22</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>재미있다</td>\n",
              "      <td>10</td>\n",
              "      <td>2018.10.20</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f1829f7-6cb0-438f-bf8d-d341466fa064')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f1829f7-6cb0-438f-bf8d-d341466fa064 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f1829f7-6cb0-438f-bf8d-d341466fa064');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./data/daum_movie_review.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평점의 분포를 살펴보도록 한다."
      ],
      "metadata": {
        "id": "44BnjwkE2ehN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MgAyuzpLxwRr",
        "outputId": "13b2d544-8f3c-40c6-f867-4dc441abaee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "df.rating.value_counts().sort_index().plot(kind='bar')\n",
        "#df.rating.plot.hist(bins=10) #히스토그램을 그릴 수도 있다.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 평점이 0부터 10으로 위치해 있어서 감성 분석과 같이 긍부정으로 결론을 내려면 평점으로부터 기준 값을 잡아 두 개의 클래스로 분류를 해야 한다.\n",
        "2. 평점이 고르게 분포하지 않고, 불균형하게 분포되어 있다.\n",
        "불균형 데이터에서 성능 측정을 위해 사용하는 지표는 정밀도와 재현율이 있다."
      ],
      "metadata": {
        "id": "MuL-9rT82lhG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOSVQSX2xwRr"
      },
      "source": [
        "\n",
        "| | 긍정으로 예측한 리뷰(PP) | 부정으로 예측한 리뷰(PN) |\n",
        "|---|---|---|\n",
        "|실제 긍정인 리뷰(P) | True positive(TP) | False negative(FN) |\n",
        "|실제 부정인 리뷰(N) | False positive(FP) | True negative(TN) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "Vqgbhlw43DyZ",
        "outputId": "b2fdfeb7-b6e1-4dc6-f831-00e7ffbaa0b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x5AGw6ZLxwRs",
        "outputId": "3ec99bc7-c5b6-4cc7-b716-3b619593a02e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train set size: 11043\n",
            "#Test set size: 3682\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data and labels into a training and a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.review, df.rating, random_state=7)\n",
        "print('#Train set size:', len(X_train))\n",
        "print('#Test set size:', len(X_test))\n",
        "\n",
        "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
        "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
        "okt = Okt()\n",
        "\n",
        "def twit_tokenizer(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
        "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
        "    result = []\n",
        "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
        "        if tag in target_tags:\n",
        "            result.append(word)\n",
        "    return result\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f00t5disxwRs",
        "outputId": "5d54ad54-839d-45a9-a68b-f6fedafee1bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Regression Train set R2 score: 0.605\n",
            "#Regression Test set R2 score: 0.395\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()  #객체를 생성\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "print('#Regression Train set R2 score: {:.3f}'.format(lr.score(X_train_tfidf, y_train)))\n",
        "print('#Regression Test set R2 score: {:.3f}'.format(lr.score(X_test_tfidf, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UxGLLn8TxwRs",
        "outputId": "b5936310-a118-42e8-fb01-a143b303ea1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Accuracy for train set: 0.888\n",
            "#Precision for train set: 0.893\n",
            "#Recall for train set: 0.969\n",
            "#F1 for train set: 0.929\n",
            "#Accuracy for test set: 0.848\n",
            "#Precision for test set: 0.868\n",
            "#Recall for test set: 0.946\n",
            "#F1 for test set: 0.905\n"
          ]
        }
      ],
      "source": [
        "y_train_senti = (y_train > 5)\n",
        "y_test_senti = (y_test > 5)\n",
        "\n",
        "y_train_predict = (lr.predict(X_train_tfidf) > 5)\n",
        "y_test_predict = (lr.predict(X_test_tfidf) > 5)\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print('#Accuracy for train set: {:.3f}'.format(accuracy_score(y_train_senti, y_train_predict)))\n",
        "print('#Precision for train set: {:.3f}'.format(precision_score(y_train_senti, y_train_predict)))\n",
        "print('#Recall for train set: {:.3f}'.format(recall_score(y_train_senti, y_train_predict)))\n",
        "print('#F1 for train set: {:.3f}'.format(f1_score(y_train_senti, y_train_predict)))\n",
        "\n",
        "print('#Accuracy for test set: {:.3f}'.format(accuracy_score(y_test_senti, y_test_predict)))\n",
        "print('#Precision for test set: {:.3f}'.format(precision_score(y_test_senti, y_test_predict)))\n",
        "print('#Recall for test set: {:.3f}'.format(recall_score(y_test_senti, y_test_predict)))\n",
        "print('#F1 for test set: {:.3f}'.format(f1_score(y_test_senti, y_test_predict)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jJng8b6BxwRt",
        "outputId": "93d70852-d879-4a4a-a0ec-90976c1d2a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Accuracy for train set: 0.878\n",
            "#Precision for train set: 0.878\n",
            "#Recall for train set: 0.973\n",
            "#F1 for train set: 0.923\n",
            "#Accuracy for test set: 0.855\n",
            "#Precision for test set: 0.866\n",
            "#Recall for test set: 0.958\n",
            "#F1 for test set: 0.910\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression #sklearn이 제공하는 logistic regression을 사용\n",
        "\n",
        "#count vector에 대해 regression을 해서 NB와 비교\n",
        "LR_clf = LogisticRegression() #분류기 선언\n",
        "LR_clf.fit(X_train_tfidf, y_train_senti) # train data를 이용하여 분류기를 학습\n",
        "\n",
        "y_train_predict = LR_clf.predict(X_train_tfidf)\n",
        "y_test_predict = LR_clf.predict(X_test_tfidf)\n",
        "\n",
        "print('#Accuracy for train set: {:.3f}'.format(accuracy_score(y_train_senti, y_train_predict)))\n",
        "print('#Precision for train set: {:.3f}'.format(precision_score(y_train_senti, y_train_predict)))\n",
        "print('#Recall for train set: {:.3f}'.format(recall_score(y_train_senti, y_train_predict)))\n",
        "print('#F1 for train set: {:.3f}'.format(f1_score(y_train_senti, y_train_predict)))\n",
        "\n",
        "print('#Accuracy for test set: {:.3f}'.format(accuracy_score(y_test_senti, y_test_predict)))\n",
        "print('#Precision for test set: {:.3f}'.format(precision_score(y_test_senti, y_test_predict)))\n",
        "print('#Recall for test set: {:.3f}'.format(recall_score(y_test_senti, y_test_predict)))\n",
        "print('#F1 for test set: {:.3f}'.format(f1_score(y_test_senti, y_test_predict)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw1El9SAxwRt"
      },
      "source": [
        "## 8.4 참고문헌\n",
        "\n",
        "Finn Årup Nielsen A new ANEW: Evaluation of a word list for sentiment analysis in microblogs. Proceedings of the ESWC2011 Workshop on 'Making Sense of Microposts': Big things come in small packages 718 in CEUR Workshop Proceedings 93-98. 2011 May.\n",
        "\n",
        "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "399MWBuAxwRu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}